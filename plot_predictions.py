"""
Utility functions to make predictions.

Main reference for code creation: https://www.learnpytorch.io/06_pytorch_transfer_learning/#6-make-predictions-on-images-from-the-test-set 
"""
import torch
import torchvision
from torchvision import transforms
import matplotlib.pyplot as plt
from typing import Dict, List, Tuple
#import ..model_dataloader as model_dataloader
from logs import logger
import model_dataloader
import model_builder
import utils
from tqdm.auto import tqdm
import torchmetrics
from torchmetrics import ConfusionMatrix
from mlxtend.plotting import plot_confusion_matrix
import random
import pandas as pd
import math
import logging
import ds4_train_model
# Set device
device = "cuda" if torch.cuda.is_available() else "cpu"
MODEL_TYPES = ["VGG8", "UnetS", "VGGVariation"]


HYPER_PARAMETERS = ds4_train_model.HYPER_PARAMETERS
TRAINING_PARAMETERS = ds4_train_model.TRAINING_PARAMETERS
HYPER_PARAMETERS['AMOUNT_SAMPLES'] = 8
HYPER_PARAMETERS['TRANSFORM'] = True                           #transformed data

MODEL_TO_TEST=[HYPER_PARAMETERS['MODEL_TYPES'][1]]


VGG8_results = {
    "VGG-8 with no dropout layer": {"approximate_accuracy": [0.2020140439271927, 0.8056148886680603, 0.9212694764137268, 0.9539212584495544, 0.969789445400238, 0.9790967106819153, 0.9845895767211914, 0.9876411557197571, 0.9896246790885925],
             "topx_accuracy": [0.2020140439271927, 0.3857186436653137, 0.5376868844032288, 0.6502898931503296, 0.7198657393455505, 0.7680805325508118, 0.8016478419303894, 0.8271284699440002, 0.8486420512199402],
             "mean_percentage": [0.2649555802345276, 0.16363076865673065, 0.11620691418647766, 0.08531902730464935, 0.062292635440826416, 0.04787300527095795, 0.037223830819129944, 0.02918172813951969, 0.02318018116056919],
             "benchmark_accuracy": [0.13625267148017883, 0.34726884961128235, 0.4163869321346283, 0.4531583786010742, 0.4754348397254944, 0.48931950330734253, 0.49740615487098694, 0.5036618709564209, 0.5061031579971313],
             "benchmark_similarity": [0.15654562099481234]},
             
    "VGG-8 with 0.2 a dropout rate": {"approximate_accuracy": [0.20048825442790985, 0.8059200644493103, 0.9243209958076477, 0.9555996060371399, 0.9691791534423828, 0.9781812429428101, 0.9836741089820862, 0.9877936840057373, 0.9899297952651978],
                 "topx_accuracy": [0.20048825442790985, 0.37549588084220886, 0.5199878215789795, 0.6364052295684814, 0.712999701499939, 0.761214554309845, 0.799359142780304, 0.8283491134643555, 0.8495575189590454],
                 "mean_percentage": [0.22499524056911469, 0.14831684529781342, 0.110710009932518, 0.08532633632421494, 0.06555279344320297, 0.05222047492861748, 0.04173072427511215, 0.033682964742183685, 0.0274681206792593],
                 "benchmark_accuracy": [0.13625267148017883, 0.34726884961128235, 0.4163869321346283, 0.4531583786010742, 0.4754348397254944, 0.48931950330734253, 0.49740615487098694, 0.5036618709564209, 0.5061031579971313],
                 "benchmark_similarity": [0.15776624961855357]},

    "VGG-8 with 0.5 a dropout rate": {"approximate_accuracy": [0.18462008237838745, 0.778150737285614, 0.9153189063072205, 0.9514800310134888, 0.9679585099220276, 0.9758926033973694, 0.9803173542022705, 0.9836741089820862, 0.9867256879806519],
             "topx_accuracy": [0.18462008237838745, 0.3523039221763611, 0.4932865500450134, 0.6051266193389893, 0.6782118082046509, 0.7313091158866882, 0.7752517461776733, 0.8100396990776062, 0.8320109844207764],
             "mean_percentage": [0.18943436443805695, 0.13180167973041534, 0.1030922532081604, 0.08304139971733093, 0.06762537360191345, 0.055789802223443985, 0.04640348255634308, 0.03884885087609291, 0.03253721818327904],
             "benchmark_accuracy": [0.13625267148017883, 0.34726884961128235, 0.4163869321346283, 0.4531583786010742, 0.4754348397254944, 0.48931950330734253, 0.49740615487098694, 0.5036618709564209, 0.5061031579971313],
             "benchmark_similarity": [0.14144034177601464]},

    "VGG-8 with no ReLU activation functions": {"approximate_accuracy": [0.18950259685516357, 0.7818126082420349, 0.9055538773536682, 0.9391211271286011, 0.9584985971450806, 0.9684162139892578, 0.9752822518348694, 0.9794018864631653, 0.9835215210914612],
             "topx_accuracy": [0.18950259685516357, 0.36740922927856445, 0.5013732314109802, 0.6124504208564758, 0.6864510178565979, 0.7357339262962341, 0.7732682228088379, 0.8004271984100342, 0.8231614232063293],
             "mean_percentage": [0.29279300570487976, 0.1630874127149582, 0.10867808759212494, 0.0763493999838829, 0.05544247105717659, 0.04157719761133194, 0.031792379915714264, 0.024682097136974335, 0.019582001492381096],
             "benchmark_accuracy": [0.13625267148017883, 0.34726884961128235, 0.4163869321346283, 0.4531583786010742, 0.4754348397254944, 0.48931950330734253, 0.49740615487098694, 0.5036618709564209, 0.5061031579971313],
             "benchmark_similarity": [0.15090021361000916]},

    "VGG-8 with one fully connected layer with ReLU activation function": {"approximate_accuracy": [0.2178822159767151, 0.82575523853302, 0.9266096949577332, 0.9557521939277649, 0.9684162139892578, 0.9774183630943298, 0.982453465461731, 0.9865731000900269, 0.9891669154167175],
             "topx_accuracy": [0.2178822159767151, 0.404333233833313, 0.548062264919281, 0.6672261357307434, 0.7351235747337341, 0.7819651961326599, 0.817058265209198, 0.8400976657867432, 0.8605431914329529],
             "mean_percentage": [0.2802426815032959, 0.16757065057754517, 0.11618851870298386, 0.08365178108215332, 0.05935443937778473, 0.04471253603696823, 0.03409074991941452, 0.02648061327636242, 0.020770370960235596],
             "benchmark_accuracy": [0.13625267148017883, 0.34726884961128235, 0.4163869321346283, 0.4531583786010742, 0.4754348397254944, 0.48931950330734253, 0.49740615487098694, 0.5036618709564209, 0.5061031579971313],
             "benchmark_similarity": [0.17348184314922185]},  

    "VGG-8 with one final fully connected layer": {"approximate_accuracy": [0.21345743536949158, 0.817821204662323, 0.9192859530448914, 0.9467501044273376, 0.9624656438827515, 0.9722306728363037, 0.9771131873130798, 0.9809277057647705, 0.9851998686790466],
             "topx_accuracy": [0.21345743536949158, 0.4050961136817932, 0.5505034923553467, 0.6690570712089539, 0.730546236038208, 0.7761672139167786, 0.8138541579246521, 0.8387244343757629, 0.8599328398704529],
             "mean_percentage": [0.30071964859962463, 0.17123648524284363, 0.11454089730978012, 0.0799182578921318, 0.05500723049044609, 0.040898002684116364, 0.031070275232195854, 0.023672442883253098, 0.0185958631336689],
             "benchmark_accuracy": [0.13625267148017883, 0.34726884961128235, 0.4163869321346283, 0.4531583786010742, 0.4754348397254944, 0.48931950330734253, 0.49740615487098694, 0.5036618709564209, 0.5061031579971313],
             "benchmark_similarity": [0.17210863594751297]},

}


UnetS_results = {
    "Unet-S with no dropout layer": {"approximate_accuracy": [0.24382056295871735, 0.8162953853607178, 0.9122673273086548, 0.9414098262786865, 0.9578883051872253, 0.9725358486175537, 0.9789441823959351, 0.982453465461731, 0.9861153364181519],
             "topx_accuracy": [0.24382056295871735, 0.4476655423641205, 0.5942935347557068, 0.7055233716964722, 0.7657918930053711, 0.8104974031448364, 0.8397924900054932, 0.8617638349533081, 0.8785474300384521],
             "mean_percentage": [0.2416980117559433, 0.19848085939884186, 0.15367789566516876, 0.12088427692651749, 0.06965776532888412, 0.05096011981368065, 0.03314070776104927, 0.0245947428047657, 0.01836145482957363],
             "benchmark_accuracy": [0.13625267148017883, 0.34726884961128235, 0.4163869321346283, 0.4531583786010742, 0.4754348397254944, 0.48931950330734253, 0.49740615487098694, 0.5036618709564209, 0.5061031579971313],
             "benchmark_similarity": [0.22947818126335062]},

    "Unet-S with a 0.1 dropout rate": {"approximate_accuracy": [0.21345743536949158, 0.817821204662323, 0.9192859530448914, 0.9467501044273376, 0.9624656438827515, 0.9722306728363037, 0.9771131873130798, 0.9809277057647705, 0.9851998686790466],
             "topx_accuracy": [0.21345743536949158, 0.4050961136817932, 0.5505034923553467, 0.6690570712089539, 0.730546236038208, 0.7761672139167786, 0.8138541579246521, 0.8387244343757629, 0.8599328398704529],
             "mean_percentage": [0.30071964859962463, 0.17123648524284363, 0.11454089730978012, 0.0799182578921318, 0.05500723049044609, 0.040898002684116364, 0.031070275232195854, 0.023672442883253098, 0.0185958631336689],
             "benchmark_accuracy": [0.13625267148017883, 0.34726884961128235, 0.4163869321346283, 0.4531583786010742, 0.4754348397254944, 0.48931950330734253, 0.49740615487098694, 0.5036618709564209, 0.5061031579971313],
             "benchmark_similarity": [0.17210863594751297]},

    "Unet-S with a 0.2 dropout rate": {"approximate_accuracy": [0.22932560741901398, 0.8185840845108032, 0.9052487015724182, 0.9375953674316406, 0.9557521939277649, 0.9691791534423828, 0.9757400155067444, 0.9806225299835205, 0.9858102202415466],
             "topx_accuracy": [0.22932560741901398, 0.4246261715888977, 0.5712541937828064, 0.6937748193740845, 0.747787594795227, 0.7961550354957581, 0.8217881917953491, 0.8433017730712891, 0.8582544922828674],
             "mean_percentage": [0.23851902782917023, 0.19943466782569885, 0.15198968350887299, 0.12102257460355759, 0.06920585036277771, 0.05274972692131996, 0.03619479387998581, 0.027980986982584, 0.021214349195361137],
             "benchmark_accuracy": [0.13625267148017883, 0.34726884961128235, 0.4163869321346283, 0.4531583786010742, 0.4754348397254944, 0.48931950330734253, 0.49740615487098694, 0.5036618709564209, 0.5061031579971313],
             "benchmark_similarity": [0.2125419591089411]},

    "Unet-S with a 0.5 dropout rate": {"approximate_accuracy": [0.18980775773525238, 0.7345132827758789, 0.8597803115844727, 0.9177601337432861, 0.943545937538147, 0.960787296295166, 0.9717729687690735, 0.9780286550521851, 0.9832163453102112],
             "topx_accuracy": [0.18980775773525238, 0.35047298669815063, 0.47421422600746155, 0.5860543251037598, 0.6501373052597046, 0.7010985612869263, 0.7398535013198853, 0.7706744074821472, 0.7940189242362976],
             "mean_percentage": [0.17063581943511963, 0.13697972893714905, 0.1039704903960228, 0.08200210332870483, 0.053726889193058014, 0.042172107845544815, 0.03191068768501282, 0.025636235252022743, 0.020567242056131363],
             "benchmark_accuracy": [0.13625267148017883, 0.34726884961128235, 0.4163869321346283, 0.4531583786010742, 0.4754348397254944, 0.48931950330734253, 0.49740615487098694, 0.5036618709564209, 0.5061031579971313],
             "benchmark_similarity": [0.1530363137015563]},

}


ad_grid_results = {
    "Trained with no adequate input":{"Tested with no adequate input": {"approximate_accuracy": [0.2548062205314636, 0.8243820667266846, 0.9060115814208984, 0.9395788908004761, 0.9581934809684753, 0.9705523252487183, 0.9766554832458496, 0.9818431735038757, 0.9861153364181519],
                                                            "topx_accuracy": [0.2548062205314636, 0.44736039638519287, 0.6000915765762329, 0.712999701499939, 0.7689960598945618, 0.8104974031448364, 0.8378089666366577, 0.8596277236938477, 0.8767164945602417],
                                                            "mean_percentage": [0.23534640669822693, 0.1851395070552826, 0.1386747807264328, 0.10815013200044632, 0.05992474779486656, 0.044462304562330246, 0.029825620353221893, 0.02280992455780506, 0.01717342622578144],
                                                            "benchmark_accuracy": [0.13625267148017883, 0.34726884961128235, 0.4163869321346283, 0.4531583786010742, 0.4754348397254944, 0.48931950330734253, 0.49740615487098694, 0.5036618709564209, 0.5061031579971313],
                                                            "benchmark_similarity": [0.23695453158376564]},
                                      "Tested with 10 adequate inputs": {"approximate_accuracy": [0.26838570833206177, 0.8613060712814331, 0.9385108351707458, 0.9627708196640015, 0.9766554832458496, 0.9842844009399414, 0.9880988597869873, 0.991608202457428, 0.9938968420028687],
                                                            "topx_accuracy": [0.26838570833206177, 0.47482454776763916, 0.6335062384605408, 0.7537381649017334, 0.8079035878181458, 0.8498626947402954, 0.8753433227539062, 0.895636260509491, 0.9119621515274048],
                                                            "mean_percentage": [0.24686872959136963, 0.19415870308876038, 0.14435920119285583, 0.11245501041412354, 0.06155522167682648, 0.045179255306720734, 0.02991992048919201, 0.022656962275505066, 0.01681385189294815],
                                                            "benchmark_accuracy": [0.1464754343032837, 0.3649679720401764, 0.4334757328033447, 0.4678059220314026, 0.4887091815471649, 0.5009154677391052, 0.5074763298034668, 0.5126640200614929, 0.5141897797584534],
                                                            "benchmark_similarity": [0.2511443393347574]},
                                      "Tested with 20 adequate inputs": {"approximate_accuracy": [0.2770827114582062, 0.8797680735588074, 0.9516326189041138, 0.9713152050971985, 0.9816905856132507, 0.9873359799385071, 0.9906927347183228, 0.9929813742637634, 0.9948123097419739],
                                                            "topx_accuracy": [0.2770827114582062, 0.4917607605457306, 0.6562404632568359, 0.7773878574371338, 0.8292645812034607, 0.8683246970176697, 0.8916692137718201, 0.9110466837882996, 0.9267622828483582],
                                                            "mean_percentage": [0.25536084175109863, 0.2005140334367752, 0.14802877604961395, 0.11466241627931595, 0.06038869172334671, 0.043679896742105484, 0.028147010132670403, 0.021056998521089554, 0.015354295261204243],
                                                            "benchmark_accuracy": [0.15135794878005981, 0.3777845501899719, 0.443545937538147, 0.4749771058559418, 0.49404942989349365, 0.5054928064346313, 0.5108330845832825, 0.5152578353881836, 0.5164784789085388],
                                                            "benchmark_similarity": [0.2630454684162344]},                                                            


                                     },

    "Trained with 10 adequate inputs":{"Tested with no adequate input": {"approximate_accuracy": [0.2462618201971054, 0.8252975344657898, 0.9015868306159973, 0.9365273118019104, 0.9542264342308044, 0.9668904542922974, 0.9749771356582642, 0.9807751178741455, 0.9839792251586914],
                                                            "topx_accuracy": [0.2462618201971054, 0.4516325891017914, 0.6031430959701538, 0.7154409289360046, 0.7665547728538513, 0.8130912184715271, 0.8379615545272827, 0.8606957793235779, 0.8764113783836365],
                                                            "mean_percentage": [0.24028877913951874, 0.1958571970462799, 0.14601117372512817, 0.11229611933231354, 0.06195083633065224, 0.045059528201818466, 0.028445329517126083, 0.02065260522067547, 0.015033241361379623],
                                                            "benchmark_accuracy": [0.13625267148017883, 0.34726884961128235, 0.4163869321346283, 0.4531583786010742, 0.4754348397254944, 0.48931950330734253, 0.49740615487098694, 0.5036618709564209, 0.5061031579971313],
                                                            "benchmark_similarity": [0.22947818126335062]},
                                      "Tested with 10 adequate inputs": {"approximate_accuracy": [0.25984132289886475, 0.8674092292785645, 0.9395788908004761, 0.9656698107719421, 0.9781812429428101, 0.9861153364181519, 0.990997850894928, 0.9934391379356384, 0.9951174855232239],
                                                            "topx_accuracy": [0.25984132289886475, 0.47772353887557983, 0.6379310488700867, 0.7561794519424438, 0.8075984120368958, 0.8547452092170715, 0.8791577816009521, 0.9017394185066223, 0.9171498417854309],
                                                            "mean_percentage": [0.25334590673446655, 0.20665420591831207, 0.15290483832359314, 0.11759219318628311, 0.06416141986846924, 0.04641250520944595, 0.0290540661662817, 0.020913096144795418, 0.01502190064638853],
                                                            "benchmark_accuracy": [0.1464754343032837, 0.3649679720401764, 0.4334757328033447, 0.4678059220314026, 0.4887091815471649, 0.5009154677391052, 0.5074763298034668, 0.5126640200614929, 0.5141897797584534],
                                                            "benchmark_similarity": [0.24534635337198657]},
                                      "Tested with 20 adequate inputs": {"approximate_accuracy": [0.269301176071167, 0.8878547549247742, 0.9528532028198242, 0.9736039042472839, 0.9838266968727112, 0.9897772073745728, 0.9929813742637634, 0.9946597218513489, 0.9957277774810791],
                                                            "topx_accuracy": [0.269301176071167, 0.4969484210014343, 0.6611229777336121, 0.778303325176239, 0.8295697569847107, 0.8751907348632812, 0.8976197838783264, 0.9179127216339111, 0.9317973852157593],
                                                            "mean_percentage": [0.2627596855163574, 0.2144399881362915, 0.15739835798740387, 0.12038557231426239, 0.06361865252256393, 0.04547359049320221, 0.027654604986310005, 0.01964608021080494, 0.013834752142429352],
                                                            "benchmark_accuracy": [0.15135794878005981, 0.3777845501899719, 0.443545937538147, 0.4749771058559418, 0.49404942989349365, 0.5054928064346313, 0.5108330845832825, 0.5152578353881836, 0.5164784789085388],
                                                            "benchmark_similarity": [0.2599938968568813]},                                                            


                                     },

    "Trained with 20 adequate inputs":{"Tested with no adequate input": {"approximate_accuracy": [0.2506866157054901, 0.8213304877281189, 0.9012816548347473, 0.9333231449127197, 0.9510222673416138, 0.9652121067047119, 0.9739090800285339, 0.9795544743537903, 0.9848946928977966],
                                                            "topx_accuracy": [0.2506866157054901, 0.44949647784233093, 0.5999389886856079, 0.7088800668716431, 0.7645712494850159, 0.8072932362556458, 0.8304852247238159, 0.8533719778060913, 0.8696978688240051],
                                                            "mean_percentage": [0.2462838739156723, 0.1953076422214508, 0.14395567774772644, 0.11026348918676376, 0.06122045964002609, 0.04547344148159027, 0.029678845778107643, 0.022251851856708527, 0.016679726541042328],
                                                            "benchmark_accuracy": [0.13625267148017883, 0.34726884961128235, 0.4163869321346283, 0.4531583786010742, 0.4754348397254944, 0.48931950330734253, 0.49740615487098694, 0.5036618709564209, 0.5061031579971313],
                                                            "benchmark_similarity": [0.23436069575831553]},
                                      "Tested with 10 adequate inputs": {"approximate_accuracy": [0.26457124948501587, 0.8631370067596436, 0.9377479553222656, 0.9635336995124817, 0.9743667840957642, 0.9838266968727112, 0.9890143275260925, 0.9919133186340332, 0.9945071935653687],
                                                            "topx_accuracy": [0.26457124948501587, 0.4749771058559418, 0.6330485343933105, 0.7473298907279968, 0.8033261895179749, 0.84787917137146, 0.8712236881256104, 0.8945682048797607, 0.9101312160491943],
                                                            "mean_percentage": [0.25888967514038086, 0.20519539713859558, 0.1503981351852417, 0.11486438661813736, 0.06276693940162659, 0.04630783572793007, 0.030029421672225, 0.022321494296193123, 0.016529463231563568],
                                                            "benchmark_accuracy": [0.1464754343032837, 0.3649679720401764, 0.4334757328033447, 0.4678059220314026, 0.4887091815471649, 0.5009154677391052, 0.5074763298034668, 0.5126640200614929, 0.5141897797584534],
                                                            "benchmark_similarity": [0.24992371071101618]},
                                      "Tested with 20 adequate inputs": {"approximate_accuracy": [0.2749466001987457, 0.8852608799934387, 0.951937735080719, 0.9726884365081787, 0.9813854098320007, 0.9879462718963623, 0.9919133186340332, 0.9938968420028687, 0.9958803653717041],
                                                            "topx_accuracy": [0.2749466001987457, 0.4958803653717041, 0.6576136946678162, 0.7729630470275879, 0.8272810578346252, 0.8713762760162354, 0.8913640379905701, 0.9139456748962402, 0.9273725748062134],
                                                            "mean_percentage": [0.26814720034599304, 0.21281380951404572, 0.15422478318214417, 0.11669672280550003, 0.06139132007956505, 0.0445370152592659, 0.02819886989891529, 0.020666901022195816, 0.015078886412084103],
                                                            "benchmark_accuracy": [0.15135794878005981, 0.3777845501899719, 0.443545937538147, 0.4749771058559418, 0.49404942989349365, 0.5054928064346313, 0.5108330845832825, 0.5152578353881836, 0.5164784789085388],
                                                            "benchmark_similarity": [0.26472383277387856]},                                                            


                                     }                                     
}




ad_sshape_results = {
    "Trained with no adequate input":{"Tested with no adequate input": {"approximate_accuracy": [0.25221237540245056, 0.8281965255737305, 0.91318279504776, 0.9444614052772522, 0.9597192406654358, 0.969789445400238, 0.9772657752037048, 0.9832163453102112, 0.9868782162666321],
                                                            "topx_accuracy": [0.25221237540245056, 0.4554470479488373, 0.6145865321159363, 0.7227647304534912, 0.7752517461776733, 0.8188892006874084, 0.8440647125244141, 0.8631370067596436, 0.8817515969276428],
                                                            "mean_percentage": [0.2479751706123352, 0.20009875297546387, 0.1485515683889389, 0.11267439275979996, 0.059121355414390564, 0.0434199683368206, 0.028305483981966972, 0.02177831530570984, 0.016322894021868706],
                                                            "benchmark_accuracy": [0.13625267148017883, 0.34726884961128235, 0.4163869321346283, 0.4531583786010742, 0.4754348397254944, 0.48931950330734253, 0.49740615487098694, 0.5036618709564209, 0.5061031579971313],
                                                            "benchmark_similarity": [0.22566371681415928]},
                                      "Tested with 10 adequate inputs": {"approximate_accuracy": [0.26380836963653564, 0.8599328398704529, 0.9391211271286011, 0.9642966389656067, 0.9777235388755798, 0.9845895767211914, 0.9900823831558228, 0.9929813742637634, 0.9949648976325989],
                                                            "topx_accuracy": [0.26380836963653564, 0.47909674048423767, 0.643729031085968, 0.7551113963127136, 0.8095819354057312, 0.8524565100669861, 0.8777845501899719, 0.8977723717689514, 0.9151663184165955],
                                                            "mean_percentage": [0.25957873463630676, 0.20979294180870056, 0.1546056568622589, 0.11697977036237717, 0.06044900044798851, 0.04391414299607277, 0.02821820229291916, 0.02148299477994442, 0.01592886447906494],
                                                            "benchmark_accuracy": [0.14403417706489563, 0.36237412691116333, 0.4314922094345093, 0.46628013253211975, 0.4882514476776123, 0.5010680556297302, 0.5082392692565918, 0.5141897797584534, 0.5157155990600586],
                                                            "benchmark_similarity": [0.23893805309734514]},
                                      "Tested with 20 adequate inputs": {"approximate_accuracy": [0.27174243330955505, 0.8785474300384521, 0.9510222673416138, 0.9714677929878235, 0.9830637574195862, 0.9879462718963623, 0.9922184944152832, 0.9946597218513489, 0.9960329532623291],
                                                            "topx_accuracy": [0.27174243330955505, 0.4992371201515198, 0.6692096590995789, 0.7802868485450745, 0.8310955166816711, 0.8713762760162354, 0.895483672618866, 0.9145559668540955, 0.931034505367279],
                                                            "mean_percentage": [0.26751360297203064, 0.21627846360206604, 0.1588631272315979, 0.11910119652748108, 0.05887427181005478, 0.042238399386405945, 0.026556847617030144, 0.01996653340756893, 0.014563650824129581],
                                                            "benchmark_accuracy": [0.14967958629131317, 0.37564846873283386, 0.443240761756897, 0.4765028953552246, 0.4967958629131317, 0.508391797542572, 0.5144949555397034, 0.5196826457977295, 0.5210558176040649],
                                                            "benchmark_similarity": [0.25465364662801343]},                                                            


                                     },
                                  
    "Trained with 10 adequate inputs":{"Tested with no adequate input": {"approximate_accuracy": [0.2535856068134308, 0.8233140110969543, 0.9116569757461548, 0.9444614052772522, 0.9598718285560608, 0.9739090800285339, 0.9803173542022705, 0.9853524565696716, 0.9888617396354675],
                                                            "topx_accuracy": [0.2535856068134308, 0.46170276403427124, 0.6057369709014893, 0.7145254611968994, 0.7656393051147461, 0.8133963942527771, 0.8405553698539734, 0.8620689511299133, 0.8777845501899719],
                                                            "mean_percentage": [0.23406179249286652, 0.18810148537158966, 0.14191092550754547, 0.10917608439922333, 0.06165756657719612, 0.0463976189494133, 0.030760975554585457, 0.02385280653834343, 0.017857331782579422],
                                                            "benchmark_accuracy": [0.13625267148017883, 0.34726884961128235, 0.4163869321346283, 0.4531583786010742, 0.4754348397254944, 0.48931950330734253, 0.49740615487098694, 0.5036618709564209, 0.5061031579971313],
                                                            "benchmark_similarity": [0.21833994507171192]},
                                      "Tested with 10 adequate inputs": {"approximate_accuracy": [0.26487642526626587, 0.8585596680641174, 0.9411046504974365, 0.9662801623344421, 0.9774183630943298, 0.9871833920478821, 0.991303026676178, 0.9940494298934937, 0.9958803653717041],
                                                            "topx_accuracy": [0.26487642526626587, 0.4871833920478821, 0.6376258730888367, 0.7506865859031677, 0.8024107217788696, 0.8506255745887756, 0.8770216703414917, 0.8983826637268066, 0.913335382938385],
                                                            "mean_percentage": [0.24511919915676117, 0.19685180485248566, 0.14727374911308289, 0.11257293820381165, 0.06244762986898422, 0.04654411971569061, 0.030397705733776093, 0.02332863211631775, 0.01722940057516098],
                                                            "benchmark_accuracy": [0.14403417706489563, 0.36237412691116333, 0.4314922094345093, 0.46628013253211975, 0.4882514476776123, 0.5010680556297302, 0.5082392692565918, 0.5141897797584534, 0.5157155990600586],
                                                            "benchmark_similarity": [0.23207201708880074]},
                                      "Tested with 20 adequate inputs": {"approximate_accuracy": [0.2535856068134308, 0.8233140110969543, 0.9116569757461548, 0.9444614052772522, 0.9598718285560608, 0.9739090800285339, 0.9803173542022705, 0.9853524565696716, 0.9888617396354675],
                                                            "topx_accuracy": [0.2535856068134308, 0.46170276403427124, 0.6057369709014893, 0.7145254611968994, 0.7656393051147461, 0.8133963942527771, 0.8405553698539734, 0.8620689511299133, 0.8777845501899719],
                                                            "mean_percentage": [0.23406179249286652, 0.18810148537158966, 0.14191092550754547, 0.10917608439922333, 0.06165756657719612, 0.0463976189494133, 0.030760975554585457, 0.02385280653834343, 0.017857331782579422],
                                                            "benchmark_accuracy": [0.13625267148017883, 0.34726884961128235, 0.4163869321346283, 0.4531583786010742, 0.4754348397254944, 0.48931950330734253, 0.49740615487098694, 0.5036618709564209, 0.5061031579971313],
                                                            "benchmark_similarity": [0.21833994507171192]},                                                            


                                     },

    "Trained with 20 adequate inputs":{"Tested with no adequate input": {"approximate_accuracy": [0.245498925447464, 0.8217881917953491, 0.9075374007225037, 0.9377479553222656, 0.9542264342308044, 0.9665852785110474, 0.9748245477676392, 0.9794018864631653, 0.9833689332008362],
                                                            "topx_accuracy": [0.245498925447464, 0.45727798342704773, 0.6010070443153381, 0.7116264700889587, 0.7654867172241211, 0.8094293475151062, 0.8362832069396973, 0.8584070801734924, 0.873970091342926],
                                                            "mean_percentage": [0.2507646083831787, 0.19804441928863525, 0.14721465110778809, 0.11232297867536545, 0.06345808506011963, 0.047198597341775894, 0.029947560280561447, 0.022275177761912346, 0.016651902347803116],
                                                            "benchmark_accuracy": [0.13625267148017883, 0.34726884961128235, 0.4163869321346283, 0.4531583786010742, 0.4754348397254944, 0.48931950330734253, 0.49740615487098694, 0.5036618709564209, 0.5061031579971313],
                                                            "benchmark_similarity": [0.23848031736344216]},
                                      "Tested with 10 adequate inputs": {"approximate_accuracy": [0.26045164465904236, 0.8581019043922424, 0.9392737150192261, 0.9629234075546265, 0.9752822518348694, 0.9830637574195862, 0.9884040355682373, 0.991150438785553, 0.9935917258262634],
                                                            "topx_accuracy": [0.26045164465904236, 0.4844369888305664, 0.635032057762146, 0.748245358467102, 0.8034787774085999, 0.84787917137146, 0.874122679233551, 0.895331084728241, 0.9102838039398193],
                                                            "mean_percentage": [0.26351940631866455, 0.20803703367710114, 0.153137668967247, 0.11626240611076355, 0.06462408602237701, 0.047558415681123734, 0.02972913533449173, 0.021828729659318924, 0.016069108620285988],
                                                            "benchmark_accuracy": [0.14403417706489563, 0.36237412691116333, 0.4314922094345093, 0.46628013253211975, 0.4882514476776123, 0.5010680556297302, 0.5082392692565918, 0.5141897797584534, 0.5157155990600586],
                                                            "benchmark_similarity": [0.25267012511443393]},
                                      "Tested with 20 adequate inputs": {"approximate_accuracy": [0.2691486179828644, 0.8793103694915771, 0.952090322971344, 0.9720781445503235, 0.9818431735038757, 0.9871833920478821, 0.990997850894928, 0.9929813742637634, 0.9948123097419739],
                                                            "topx_accuracy": [0.2691486179828644, 0.5016783475875854, 0.6595972180366516, 0.7731156349182129, 0.8266707062721252, 0.8701556324958801, 0.895025908946991, 0.9148611426353455, 0.9282880425453186],
                                                            "mean_percentage": [0.2734130918979645, 0.21507827937602997, 0.15703997015953064, 0.1179894283413887, 0.06308390945196152, 0.04581847041845322, 0.027785396203398705, 0.020136984065175056, 0.01457610260695219],
                                                            "benchmark_accuracy": [0.14967958629131317, 0.37564846873283386, 0.443240761756897, 0.4765028953552246, 0.4967958629131317, 0.508391797542572, 0.5144949555397034, 0.5196826457977295, 0.5210558176040649],
                                                            "benchmark_similarity": [0.27036924015868175]},                                                            


                                     }                                     
}

 
def plot_accuracy(model_type=None,plot=True):
    """Plots training curves of a results dictionary.

    Args:
        results (dict): dictionary containing list of values, e.g.
            {"train_loss": [...],
             "train_acc": [...],
             "test_loss": [...],
             "test_acc": [...]}
    """
    results = VGG8_results[model_type]
    
    start=1
    end=10
    # Get the loss values of the results dictionary (training and test)
    approx_acc = results['approximate_accuracy']
    mean_percentage = results['mean_percentage']
    topx_acc = results['topx_accuracy']
    benchmark_accuracy = results['benchmark_accuracy']
    benchmark_similarity = results['benchmark_similarity']    
    

    # Figure out how many epochs there were
    
    accuracy_amount = range(start,end)
    if(plot):
        # Setup a plot 
        plt.figure(figsize=(15, 7))

        # Plot loss
        #plt.subplot(1, 2, 1)
        plt.plot(accuracy_amount, approx_acc, label='Approximate Accuracy')
        plt.plot(accuracy_amount, topx_acc, label='Top N Accuracy')
        plt.plot(accuracy_amount, benchmark_accuracy, label='Benchmark Accuracy')

        # plt.plot(accuracy_amount, mean_percentage, label='mean_percentage')
        plt.title('VGG')
        plt.ylabel('Accuracy')
        plt.xlabel('n')
        plt.legend()
        plt.show()
    return results




def main():



    logger.logging_config(logs_save=False)
    #model_to_test=(HYPER_PARAMETERS['MODEL_TYPES'][1],HYPER_PARAMETERS['MODEL_TYPES'][2])
    #model_type=HYPER_PARAMETERS['MODEL_TYPES'][2],
    result_dic=[]
    for model_type in VGG8_results.keys():
        accuracy_results=plot_accuracy(model_type=model_type)
        logging.info(f"[ACCURACY] Results: {accuracy_results}")
        #print(accuracy_results)
        result_dic.append(accuracy_results)
    plot_model_accuracies(result_dic)
    #do_predictions_confusion_matrix(flattened=True)
    #do_predictions_confusion_matrix(model="CNNwithDistinctiveVGG")
    #plot_confusionmatrix









MODEL_TO_TEST=1


def plot_model_accuracies(result_dic):
    accuracy_amount =  range(1,11)
    # Setup a plot 
    plt.figure(figsize=(15, 7))
    for x in range(len(result_dic)):
        model=result_dic[x]
        accuracy_amount =  range(1,len(model['approximate_accuracy'])+1)
        plt.plot(accuracy_amount, model['approximate_accuracy'], label=f'{MODEL_TO_TEST[x]} Approximate Accuracy', color=f'C{x}')
        plt.plot(accuracy_amount, model['topx_accuracy'], label=f'{MODEL_TO_TEST[x]} Top Values Accuracy', linestyle='--', color=f'C{x}')
    # plt.plot(accuracy_amount, mean_percentage, label='mean_percentage')
    plt.title('Accuracy')
    plt.xlabel('Accuracy Distance')
    plt.legend()
    plt.show()
    plt.figure(figsize=(15, 7))
    for x in range(len(result_dic)):
        model=result_dic[x]
        accuracy_amount =  range(1,len(model['approximate_accuracy'])+1)
        plt.plot(accuracy_amount, model['mean_percentage'], label=f'{MODEL_TO_TEST[x]} Mean Percentage', color=f'C{x}')
        #plt.plot(accuracy_amount, model['topx_accuracy'], label=f'{model["model_type"]} Top Values Accuracy')
    # plt.plot(accuracy_amount, mean_percentage, label='mean_percentage')
    plt.title('Confidence Comparison')
    plt.xlabel('Accuracy Distance')
    plt.legend()
    plt.show()    
    return result_dic

def do_predictions(model_type= "VGG"):
    """Makes prediction with a model and plots 5 different test samples with respective results.
    

    Args:
    model(string): Type of model to be used for predicting.
    dataloader(string): Type of dataset to be used for predicting.

    Returns:
    Plot of 5 samples
    Plot of confusion matrix
    """
    utils.seed_generator(SEED=TRAINING_PARAMETERS['LOAD_SEED'])
    train_dataloader,test_dataloader,classes = model_dataloader.create_dataloader(model_type=model_type, batch_size=TRAINING_PARAMETERS['BATCH_SIZE'], transform=HYPER_PARAMETERS['TRANSFORM'], amount_samples=HYPER_PARAMETERS['AMOUNT_SAMPLES'], window_size=HYPER_PARAMETERS['WINDOW_SIZE'])
    model = model_builder.choose_model(model_type=model_type,output_shape=classes,device=device,window_size=HYPER_PARAMETERS['WINDOW_SIZE'])
    model,_=utils.load_model(model= model, model_type=model_type, device=device)
    utils.seed_generator(SEED=TRAINING_PARAMETERS['LOAD_SEED'])
    y_pred,y_list,X_list,y_logit_list,y_preds_percent=make_prediction_all_results(model_type=model_type,model=model,test_dataloader=test_dataloader)
    accuracy_results=print_metrics(y_pred,y_list,y_preds_percent,classes,model_type)
    benchmark_similarity,benchmark_accuracy=calculate_max_accuracy(X_list,y_list,y_preds_percent)
    accuracy_results['benchmark_accuracy']=benchmark_accuracy
    accuracy_results['benchmark_similarity']=benchmark_similarity
    y_list,y_logit_list,y_preds_percent=reshape_tensor(y_list=y_list,y_logit_list=y_logit_list,y_preds_percent=y_preds_percent)
    make_plots(y_pred,X_list,y_list,y_logit_list,y_preds_percent)  
    return accuracy_results










def make_prediction_all_results(model,test_dataloader,model_type):
    y_pred_list = []
    y_list=[]
    X_list=[]
    y_logit_list=[]
    y_preds_percent=[]
    model.eval()
    logging.info(f"Making predictions:")

    with torch.inference_mode():
      for batch, (X, y) in tqdm(enumerate(test_dataloader), desc="Working", total=len(test_dataloader)):
        # Send data and targets to target device
        y_list.append(y.cpu())
        X_list.append(X.cpu())
        X, y = X.to(device), y.to(device)
        # Do the forward pass
        y_logit = model(X)
        # Turn predictions from logits -> prediction probabilities -> predictions labels
        if(model_type==MODEL_TYPES[1]):
            y_pred_percentage = torch.sigmoid(y_logit)
        else:
            y_pred_percentage=torch.softmax(y_logit, dim=1)
        y_pred = torch.argmax(y_pred_percentage, dim=1) 
        y_pred_list.append(y_pred.cpu())
        y_logit_list.append(y_logit.cpu())
        y_preds_percent.append(y_pred_percentage.cpu())
    # Concatenate list of predictions into a tensor
    y_list_tensor=torch.cat(y_list)
    y_pred_tensor = torch.cat(y_pred_list)
    X_list_tensor=torch.cat(X_list)
    y_logit_list_tensor=torch.cat(y_logit_list)
    y_preds_percent_tensor=torch.cat(y_preds_percent)
    return y_pred_tensor,y_list_tensor,X_list_tensor,y_logit_list_tensor,y_preds_percent_tensor
    




def make_plots(y_pred,X_list,y_list,y_logit_list,y_preds_percent):
    #def show_as_image_sequence_batch(dataset, predicted_dataset):
    #results=[X_list,y_list,y_logit_list,y_preds_percent]
    y_list,y_logit_list,y_preds_percent=reshape_tensor(y_list,y_logit_list,y_preds_percent)
    size=[4,4]
    f, arr = plt.subplots(size[0],size[1]) 
    random_samples=random.sample(range(X_list.shape[0]),k=size[0])
    for j in range(arr.shape[0]):
        i=random_samples[j]
        #print(i)
        arr[j,0].imshow(X_list[i].squeeze(0).unsqueeze(-1).numpy(), origin="lower")
        arr[j,0].set(xlabel=f"Sample: {i}, X (Input of Model)") 
        max_index = y_list[i].argmax().item()
        max_y, max_x = divmod(max_index,y_list[i].shape[-1])
        arr[j,1].imshow(y_list[i].squeeze(0).unsqueeze(-1).numpy(), origin="lower")
        arr[j,1].set(xlabel=f"y (Target), Max Value at ({max_x}, {max_y})")
        arr[j,2].imshow(y_logit_list[i].squeeze(0).unsqueeze(-1).numpy(), origin="lower")
        arr[j,2].set(xlabel=f"y_logit (Output of Model)")
        arr[j,3].imshow(y_preds_percent[i].squeeze(0).unsqueeze(-1).numpy(), origin="lower")
        #arr[j,3].set(xlabel=f"Sample: {i}, y_preds_percent")
        max_value = y_preds_percent[i].max().item()
        max_index = y_preds_percent[i].argmax().item()
        max_y, max_x = divmod(max_index, y_preds_percent[i].shape[-1])
        arr[j,3].set(xlabel=f"Predicted Percentages, Max Value: {max_value:.2f} at ({max_x}, {max_y})")
        #plt.xticks([])
        #plt.yticks([])
    # f.tight_layout()
    plt.subplots_adjust(hspace =0.4)
    plt.show()

def reshape_tensor(y_list,y_logit_list,y_preds_percent):
    if(len(y_list.shape)>2):
        return y_list,y_logit_list,y_preds_percent
    else:
        y_list=torch.reshape(y_list, (y_list.shape[0], HYPER_PARAMETERS['WINDOW_SIZE'][0], HYPER_PARAMETERS['WINDOW_SIZE'][1]))
        y_logit_list=torch.reshape(y_logit_list, (y_logit_list.shape[0], HYPER_PARAMETERS['WINDOW_SIZE'][0], HYPER_PARAMETERS['WINDOW_SIZE'][1]))
        y_preds_percent=torch.reshape(y_preds_percent, (y_preds_percent.shape[0], HYPER_PARAMETERS['WINDOW_SIZE'][0], HYPER_PARAMETERS['WINDOW_SIZE'][1]))        
    return y_list,y_logit_list,y_preds_percent






def print_metrics(y_pred,y_list,y_preds_percent,classes,model_type):
    logging.info(f"Calculating Metrics and Plotting:")
    if(model_type==MODEL_TYPES[1]):
        y_pred_index = torch.argmax(y_preds_percent.view(y_preds_percent.shape[0], -1), dim=1)  # [batch]
        y_list_index = torch.argmax(y_list.view(y_list.shape[0], -1), dim=1)  # [batch]

        return plot_accuracy_curves(y_list_index,y_pred_index,y_list,y_preds_percent,y_pred.shape[-1])

    y_old=y_list            
    y_list=torch.argmax(y_list,dim=1)
    #acc = torchmetrics.functional.accuracy(y_pred, y_list, task="multiclass", num_classes=classes)
    #print(acc)
    #f1= torchmetrics.F1Score(task="multiclass", num_classes=classes)
    #acc2= torchmetrics.Accuracy("multiclass",num_classes=classes)
    #ap = torchmetrics.AveragePrecision(task="multiclass", num_classes=classes, average=None)


    #print(
      #f"Accuracy: {acc} | \n"
      #f"Accuracy Function: {acc2(y_pred,y_list)} | \n"
      #f"F1 Function: {f1(y_pred,y_list)} | \n"
      #f"Average Precision Function: {ap(y_preds_percent,y_list)} | \n"
      #f"Confusion Matrix: {confmat(y_pred,y_list)} \n"
     # f"Confusion Matrix shape: {confmat_tensor.shape}"
    #)    
    #compare_mistakes(y_pred,y_list)
    return plot_accuracy_curves(y_list,y_pred,y_old,y_preds_percent,math.sqrt(classes))
    #confmat = ConfusionMatrix(task="multiclass", num_classes=classes)
    #confmat_tensor=confmat(y_pred,y_list)

    approx_acc_1=approximate_accuracy(y_list,y_pred,math.sqrt(classes),1)
    approx_acc_2=approximate_accuracy(y_list,y_pred,math.sqrt(classes),2)
    approx_acc_3=approximate_accuracy(y_list,y_pred,math.sqrt(classes),3)
    approx_acc_4=approximate_accuracy(y_list,y_pred,math.sqrt(classes),4)
    approx_acc_5=approximate_accuracy(y_list,y_pred,math.sqrt(classes),5)
    top_acc_2=topx_accuracy(y_old,y_preds_percent,2)
    top_acc_3=topx_accuracy(y_old,y_preds_percent,3)
    top_acc_4=topx_accuracy(y_old,y_preds_percent,4)
    top_acc_5=topx_accuracy(y_old,y_preds_percent,5)
    top_acc_6=topx_accuracy(y_old,y_preds_percent,6)
    print(f"Approximate Accuracy 1: {approx_acc_1} | Approximate Accuracy 2: {approx_acc_2} | Approximate Accuracy 3: {approx_acc_3}  | Approximate Accuracy 4: {approx_acc_4}  | Approximate Accuracy 5: {approx_acc_5} ")
    print(f"Top 2 Accuracy: {top_acc_2} | Top 3 Accuracy: {top_acc_3} | Top 4 Accuracy: {top_acc_4} | Top 5 Accuracy: {top_acc_5} | Top 6 Accuracy: {top_acc_6} ")
    #df_cfm.to_csv('data/confusion_matrix/cfmtest.csv')
    #print("saved")
    if(classes>100):
        #plt.figure(figsize = (10,7))
        df_cfm = pd.DataFrame(confmat(y_pred,y_list).numpy(), index = range(classes), columns = range(classes))
        plt.imshow(df_cfm.to_numpy())
    else:
        #plot confusion matrix
        plot_confusionmatrix(confmat_tensor)
        #more stylish plot
        #plot_conf_sklearn(y_pred_tensor=y_pred,y_target_tensor=y_list,classes=classes)





#Plot Confusion_Matrix Helper functions
def plot_confusionmatrix(confmat_tensor):
    fig, ax = plot_confusion_matrix(
        conf_mat=confmat_tensor.numpy(), # matplotlib likes working with NumPy 
        class_names=range(confmat_tensor.shape[0]), # turn the row and column labels into class names
        #figsize=(10, 7)
    )

def plot_conf_sklearn(y_pred_tensor, y_target_tensor, classes):
    from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
    cm = confusion_matrix(y_target_tensor, y_pred_tensor, labels=range(classes))
    disp = ConfusionMatrixDisplay(confusion_matrix=cm,
                                  display_labels=range(classes))
    disp.plot()



def compare_mistakes(y_pred_index,y_list_index):
    mistakes=[]
    correct_values=[]
    for x in range(y_list_index.shape[0]):
        if(y_pred_index[x]!=y_list_index[x]):
            print(
              f"x: {x} | \n"
              f"y_pred_index[x]: {y_pred_index[x]} | \n"
              f"y_list_index[x]: {y_list_index[x]} | \n"
            )
            mistakes.append(x)


def test_topx():
    y_true_list = torch.randint(0, 20, (10, 3, 3))
    y_predicted_list = torch.randint(0, 20, (10, 3, 3))
    mean_percentage,topx_accuracies=topx_accuracy(y_true_list,y_predicted_list,2)
    print("topx_accuracy",topx_accuracies)
    print("mean_percentage",mean_percentage)

def topx_accuracy(y_true_list, y_predicted_list, amount_of_values):
    topx_values, topx_indices = torch.topk(y_predicted_list.view(y_predicted_list.shape[0], -1), amount_of_values, dim=1)
    y_true_max, y_true_indices = torch.max(y_true_list.view(y_true_list.shape[0], -1), dim=1)
    matches= torch.any(y_true_indices[:,None] == topx_indices, dim=1)
    accuracy = matches.float().mean().item()
    mean_percentage=torch.mean(topx_values[:,amount_of_values-1].float())
    return mean_percentage.float().item(),accuracy

#test_topx()


def calculate_max_accuracy(X_list,y_list,y_preds_percent):
    accuracy_max=0
    accuracy_max_pred=0
    x_max_index = torch.argmax(X_list.view(X_list.shape[0], -1), dim=1)  # [batch]
    y_pred_index = torch.argmax(y_preds_percent.view(y_preds_percent.shape[0], -1), dim=1) 
    y_index = torch.argmax(y_list.view(y_list.shape[0], -1), dim=1) 
    for x in range(x_max_index.shape[0]):
        if(x_max_index[x]==y_index[x]):
            accuracy_max+=1
        if(x_max_index[x]==y_pred_index[x]):
            accuracy_max_pred+=1
    accuracy_max=accuracy_max/len(X_list)
    accuracy_max_pred=accuracy_max_pred/len(X_list)
    print(f"X_max with y_true: {accuracy_max} | X_max with y_pred: {accuracy_max_pred}")
    approx_accuracies=[]
    for x in range(1,10):
        approx_acc=approximate_accuracy(y_index,x_max_index,64,x-1)
        approx_accuracies.append(approx_acc)
        #print(f"approx_acc: {approx_acc}")
    #print(f"approx_acc: {approx_acc}")
    return accuracy_max_pred,approx_accuracies

def approximate_accuracy(y_true_list, y_predicted_list, height, distance):
    accuracies = 0
    for y_true, y_predicted in zip(y_true_list, y_predicted_list):
        y_true_height = torch.div(y_true, height, rounding_mode='floor')
        y_true_width = y_true % height
        y_predicted_height = torch.div(y_predicted, height, rounding_mode='floor')
        y_predicted_width = y_predicted % height

        # Calculate the valid neighborhood bounds for each predicted point
        height_min = torch.clamp(y_predicted_height - distance, min=0)
        height_max = torch.clamp(y_predicted_height + distance, max=height - 1)
        width_min = torch.clamp(y_predicted_width - distance, min=0)
        width_max = torch.clamp(y_predicted_width + distance, max=height - 1)

        # Check if true points fall within the corresponding neighborhood
        matches = (
            (y_true_height >= height_min) & (y_true_height <= height_max) &
            (y_true_width >= width_min) & (y_true_width <= width_max)
        )

        # Calculate accuracy for the current pair
        #accuracy = (matches.sum().item() / len(y_true))
        accuracies+=matches
    
    accuracies=accuracies/len(y_true_list)
    accuracies=accuracies.float().item()
    return accuracies


def plot_accuracy_curves(approx_y_true,approx_y_pred,topx_y_true,topx_y_pred,classes,plot=False):
    """Plots training curves of a results dictionary.

    Args:
        results (dict): dictionary containing list of values, e.g.
            {"train_loss": [...],
             "train_acc": [...],
             "test_loss": [...],
             "test_acc": [...]}
    """
    results = {"approximate_accuracy": [],
               "topx_accuracy": [],
               "mean_percentage": [],
               "benchmark_accuracy": [],
               "benchmark_similarity": []}
    
    start=1
    end=10
    for x in range(start,end):
        approx_acc=approximate_accuracy(approx_y_true,approx_y_pred,classes,x-1)
        mean_percentage,topx_acc=topx_accuracy(topx_y_true,topx_y_pred,x)
        results['approximate_accuracy'].append(approx_acc)
        results['mean_percentage'].append(mean_percentage)
        results['topx_accuracy'].append(topx_acc)
    # Get the loss values of the results dictionary (training and test)
    approx_acc = results['approximate_accuracy']
    mean_percentage = results['mean_percentage']
    topx_acc = results['topx_accuracy']
    

    # Figure out how many epochs there were
    
    accuracy_amount = range(start,end)
    if(plot):
        # Setup a plot 
        plt.figure(figsize=(15, 7))

        # Plot loss
        #plt.subplot(1, 2, 1)
        plt.plot(accuracy_amount, approx_acc, label='Approximate Accuracy')
        plt.plot(accuracy_amount, topx_acc, label='Top Values Accuracy')
        # plt.plot(accuracy_amount, mean_percentage, label='mean_percentage')
        plt.title('Accuracy')
        plt.xlabel('Accuracy Distance')
        plt.legend()
        plt.show()
    return results






if __name__ == "__main__":
    main()